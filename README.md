# ูููุฐุฌ ุชุญููู ุงููุดุงุนุฑ ูููุตูุต ุงูุนุฑุจูุฉ ูุงูุฅูุฌููุฒูุฉ

## ๐ ุงููุตู
ูุฐุง ุงููุดุฑูุน ูุณุชุฎุฏู ูููุฐุฌ BERT ูุชุนุฏุฏ ุงููุบุงุช ูุชุญููู ุงููุดุงุนุฑ ูู ุงููุตูุต ุงูุนุฑุจูุฉ ูุงูุฅูุฌููุฒูุฉ. ุงููููุฐุฌ ูุงุฏุฑ ุนูู ุชุตููู ุงููุตูุต ุฅูู ุซูุงุซ ูุฆุงุช: ุฅูุฌุงุจูุ ุณูุจูุ ููุญุงูุฏ.

## ๐ ุงููููุฒุงุช
- ุฏุนู ุงููุบุชูู ุงูุนุฑุจูุฉ ูุงูุฅูุฌููุฒูุฉ
- ุงุณุชุฎุฏุงู ูููุฐุฌ BERT ูุชุนุฏุฏ ุงููุบุงุช
- ุชุฏุฑูุจ ูุฎุตุต ุนูู ุจูุงูุงุช ุงููุญุงุฏุซุงุช
- ูุงุฌูุฉ ุณููุฉ ุงูุงุณุชุฎุฏุงู
- ูุชูุงูู ูุน Google Colab

## ๐ ุงููุชุทูุจุงุช
```bash
pip install -r requirements.txt
```

## ๐ง ุงูุชุซุจูุช ูุงูุงุณุชุฎุฏุงู

### ูู Google Colab:
1. ุงูุชุญ ุงูููู `Sentiment_Analysis.ipynb` ูู Google Colab
2. ูู ุจุชุดุบูู ุงูุฎูุงูุง ุจุงูุชุฑุชูุจ
3. ุณูุชู ุชุญููู Google Drive ุชููุงุฆูุงู

### ูู ุงูุจูุฆุฉ ุงููุญููุฉ:
1. ุชุฃูุฏ ูู ุชุซุจูุช ุงููุชุทูุจุงุช:
```bash
pip install -r requirements.txt
```
2. ุงูุชุญ ุงูููู `Sentiment_Analysis.ipynb` ูู Jupyter Notebook
3. ูู ุจุชุดุบูู ุงูุฎูุงูุง ุจุงูุชุฑุชูุจ

## ๐ ุงูุจูุงูุงุช
ูุณุชุฎุฏู ุงููุดุฑูุน ูููุงุช JSONL ุชุญุชูู ุนูู ูุญุงุฏุซุงุช ุจุงููุบุฉ ุงูุนุฑุจูุฉ. ูุชู ุชุญููู ุงููุดุงุนุฑ ุจูุงุกู ุนูู:
- ุงููููุงุช ุงูููุชุงุญูุฉ ุงูุฅูุฌุงุจูุฉ ูุงูุณูุจูุฉ
- ุงูุณูุงู ุงูุนุงู ูููุต

## ๐ค ุงููููุฐุฌ
- **ุงููููุฐุฌ ุงูุฃุณุงุณู**: `bert-base-multilingual-cased`
- **ุนุฏุฏ ุงูุชุตูููุงุช**: 3 (ุฅูุฌุงุจูุ ุณูุจูุ ูุญุงูุฏ)
- **ุทูู ุงููุต ุงูุฃูุตู**: 128 token

## ๐ ุงูุฃุฏุงุก
ูุชู ุชูููู ุงููููุฐุฌ ุจุงุณุชุฎุฏุงู:
- ุฏูุฉ ุงูุชุตููู (Accuracy)
- F1-Score

## ๐ ุงุณุชููุงู ุงูุชุฏุฑูุจ

### ูู ููุทุฉ ุงูุชููู:
```python
trainer.train(resume_from_checkpoint="path/to/checkpoint")
```

### ุชุญููู ูููุฐุฌ ูุญููุธ:
```python
model = BertForSequenceClassification.from_pretrained("path/to/checkpoint")
```

## ๐ฏ ุงูุงุณุชุฎุฏุงู

```python
# ุชุตููู ูุต ูุงุญุฏ
result = classify_sentiment("ูุฐุง ุงูููุชุฌ ุฑุงุฆุน ุฌุฏุงู")
print(f"ุงูุชุตููู: {result['label']}")
print(f"ุงูุซูุฉ: {result['confidence']:.2f}")
```

## ๐ ูููู ุงููุดุฑูุน
```
โโโ Sentiment_Analysis.ipynb    # ุงูููู ุงูุฑุฆูุณู
โโโ requirements.txt           # ุงููุชุทูุจุงุช
โโโ README.md                 # ูุฐุง ุงูููู
โโโ data/                     # ูุฌูุฏ ุงูุจูุงูุงุช (JSONL files)
```

## ๐ค ุงููุณุงููุฉ
ูุฑุญุจ ุจุงููุณุงููุงุช! ูุฑุฌู:
1. ุนูู Fork ูููุดุฑูุน
2. ุฅูุดุงุก branch ุฌุฏูุฏ ููููุฒุฉ
3. ุฅุฑุณุงู Pull Request

## ๐ ุงูุชุฑุฎูุต
ูุฐุง ุงููุดุฑูุน ูุฑุฎุต ุชุญุช ุฑุฎุตุฉ MIT.

## ๐ ุงูุชูุงุตู
ููุงุณุชูุณุงุฑุงุช ูุงูุฏุนูุ ูุฑุฌู ูุชุญ issue ูู ุงููุณุชูุฏุน.

---

# Arabic & English Sentiment Analysis Model

## ๐ Description
This project uses a multilingual BERT model for sentiment analysis in Arabic and English texts. The model can classify texts into three categories: positive, negative, and neutral.

## ๐ Features
- Support for Arabic and English languages
- Uses multilingual BERT model
- Custom training on conversational data
- Easy-to-use interface
- Google Colab compatible

## ๐ง Installation & Usage

### In Google Colab:
1. Open `Sentiment_Analysis.ipynb` in Google Colab
2. Run cells in order
3. Google Drive will be mounted automatically

### Local Environment:
1. Install requirements:
```bash
pip install -r requirements.txt
```
2. Open `Sentiment_Analysis.ipynb` in Jupyter Notebook
3. Run cells in order

## ๐ฏ Usage Example

```python
# Classify a single text
result = classify_sentiment("This product is amazing!")
print(f"Label: {result['label']}")
print(f"Confidence: {result['confidence']:.2f}")
```

## ๐ Model Performance
The model is evaluated using:
- Accuracy
- F1-Score

## ๐ค Contributing
Contributions are welcome! Please:
1. Fork the project
2. Create a feature branch
3. Submit a Pull Request

## ๐ License
This project is licensed under the MIT License.