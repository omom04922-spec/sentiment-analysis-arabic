{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "colab-setup",
   "metadata": {},
   "source": [
    "# تحليل المشاعر باستخدام Mixtral-8x7B\n",
    "\n",
    "هذا المشروع يستخدم نموذج Mixtral-8x7B مع تقنية LoRA لتحليل المشاعر في النصوص العربية والإنجليزية.\n",
    "\n",
    "## متطلبات RunPod:\n",
    "- GPU: RTX 4090 أو A100 (24GB+ VRAM)\n",
    "- RAM: 32GB+\n",
    "- Storage: 50GB+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "runpod-initial-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# إعدادات RunPod الأولية\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# التحقق من البيئة\n",
    "print('=== معلومات البيئة ===')\n",
    "print(f'Python: {sys.version}')\n",
    "print(f'Working Directory: {os.getcwd()}')\n",
    "\n",
    "# إعداد متغيرات البيئة لـ RunPod\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/workspace/cache'\n",
    "os.environ['HF_HOME'] = '/workspace/cache'\n",
    "\n",
    "# إنشاء مجلدات العمل\n",
    "os.makedirs('/workspace/cache', exist_ok=True)\n",
    "os.makedirs('/workspace/models', exist_ok=True)\n",
    "os.makedirs('/workspace/data', exist_ok=True)\n",
    "\n",
    "print('تم إعداد بيئة RunPod بنجاح!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colab-mount",
   "metadata": {},
   "outputs": [],
   "source": [
    "# تحميل Google Drive في Colab (اختياري)\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    COLAB_ENV = True\n",
    "    print('تم تحميل Google Drive بنجاح!')\n",
    "except ImportError:\n",
    "    COLAB_ENV = False\n",
    "    print('البيئة المحلية أو RunPod - لا حاجة لتحميل Drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-packages",
   "metadata": {},
   "outputs": [],
   "source": [
    "# تثبيت المكتبات المطلوبة لـ Mixtral\n",
    "!pip install transformers datasets torch scikit-learn seqeval accelerate bitsandbytes\n",
    "!pip install --upgrade transformers\n",
    "!pip install peft\n",
    "!pip install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports-and-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# استيراد المكتبات\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, BitsAndBytesConfig\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('تم استيراد جميع المكتبات بنجاح!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-paths",
   "metadata": {},
   "outputs": [],
   "source": [
    "# إعداد المسارات\n",
    "if 'COLAB_ENV' in locals() and COLAB_ENV:\n",
    "    # مسارات Google Colab\n",
    "    BASE_PATH = '/content/drive/MyDrive/sentiment_analysis'\n",
    "    DATA_PATH = os.path.join(BASE_PATH, 'data')\n",
    "    MODEL_SAVE_PATH = os.path.join(BASE_PATH, 'models')\n",
    "else:\n",
    "    # مسارات RunPod أو البيئة المحلية\n",
    "    BASE_PATH = '/workspace'\n",
    "    DATA_PATH = os.path.join(BASE_PATH, 'data')\n",
    "    MODEL_SAVE_PATH = os.path.join(BASE_PATH, 'models')\n",
    "\n",
    "# إنشاء المجلدات\n",
    "os.makedirs(DATA_PATH, exist_ok=True)\n",
    "os.makedirs(MODEL_SAVE_PATH, exist_ok=True)\n",
    "\n",
    "print(f'مسار البيانات: {DATA_PATH}')\n",
    "print(f'مسار حفظ النماذج: {MODEL_SAVE_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl_data(file_path):\n",
    "    \"\"\"تحميل بيانات JSONL\"\"\"\n",
    "    data = []\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                data.append(json.loads(line.strip()))\n",
    "        print(f'تم تحميل {len(data)} عينة من {file_path}')\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f'الملف غير موجود: {file_path}')\n",
    "        return []\n",
    "\n",
    "def simple_sentiment_analysis(text):\n",
    "    \"\"\"تحليل مشاعر بسيط باستخدام الكلمات المفتاحية\"\"\"\n",
    "    positive_words = ['جيد', 'ممتاز', 'رائع', 'أحب', 'جميل', 'good', 'great', 'excellent', 'love', 'amazing']\n",
    "    negative_words = ['سيء', 'فظيع', 'أكره', 'مروع', 'bad', 'terrible', 'hate', 'awful', 'horrible']\n",
    "    \n",
    "    text_lower = text.lower()\n",
    "    positive_count = sum(1 for word in positive_words if word in text_lower)\n",
    "    negative_count = sum(1 for word in negative_words if word in text_lower)\n",
    "    \n",
    "    if positive_count > negative_count:\n",
    "        return 2  # إيجابي\n",
    "    elif negative_count > positive_count:\n",
    "        return 0  # سلبي\n",
    "    else:\n",
    "        return 1  # محايد\n",
    "\n",
    "def prepare_data_for_model(texts, labels=None):\n",
    "    \"\"\"إعداد البيانات للنموذج\"\"\"\n",
    "    if labels is None:\n",
    "        # إنشاء تسميات تلقائية باستخدام التحليل البسيط\n",
    "        labels = [simple_sentiment_analysis(text) for text in texts]\n",
    "    \n",
    "    return list(zip(texts, labels))\n",
    "\n",
    "print('تم تعريف دوال تحميل البيانات!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-sample-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# إنشاء بيانات تجريبية للتدريب\n",
    "sample_texts = [\n",
    "    'هذا المنتج رائع جداً وأنصح به بشدة',\n",
    "    'المنتج سيء جداً ولا أنصح بشرائه أبداً',\n",
    "    'المنتج عادي، لا بأس به',\n",
    "    'أحب هذا المنتج كثيراً',\n",
    "    'أكره هذا المنتج',\n",
    "    'المنتج جيد نوعاً ما',\n",
    "    'This product is amazing and I highly recommend it',\n",
    "    'This product is terrible and I hate it',\n",
    "    'The product is okay, nothing special',\n",
    "    'I love this product so much',\n",
    "    'I really hate this product',\n",
    "    'The product is good but could be better'\n",
    "] * 100  # تكرار البيانات للحصول على عينة أكبر\n",
    "\n",
    "# إعداد البيانات\n",
    "prepared_data = prepare_data_for_model(sample_texts)\n",
    "texts, labels = zip(*prepared_data)\n",
    "\n",
    "print(f'عدد العينات: {len(texts)}')\n",
    "print(f'توزيع التسميات: {np.bincount(labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tokenizer-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# إعداد tokenizer لـ Mixtral\n",
    "model_name = 'mistralai/Mixtral-8x7B-Instruct-v0.1'\n",
    "\n",
    "print('تحميل tokenizer...')\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# إضافة pad token إذا لم يكن موجوداً\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(f'تم تحميل tokenizer: {model_name}')\n",
    "print(f'حجم المفردات: {len(tokenizer)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dataset-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "print('تم تعريف فئة Dataset!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# تقسيم البيانات\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "# إنشاء datasets\n",
    "train_dataset = SentimentDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = SentimentDataset(val_texts, val_labels, tokenizer)\n",
    "\n",
    "print(f'عدد عينات التدريب: {len(train_dataset)}')\n",
    "print(f'عدد عينات التقييم: {len(val_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# إعداد نموذج Mixtral مع quantization\n",
    "print('تحميل نموذج Mixtral...')\n",
    "\n",
    "# إعدادات quantization\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")\n",
    "\n",
    "# تحميل النموذج\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=3,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='auto',\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# إعداد LoRA\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=['q_proj', 'v_proj', 'k_proj', 'o_proj']\n",
    ")\n",
    "\n",
    "# تطبيق LoRA على النموذج\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "print('تم تحميل النموذج وإعداد LoRA بنجاح!')\n",
    "print(f'عدد المعاملات القابلة للتدريب: {model.num_parameters():,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training-args",
   "metadata": {},
   "outputs": [],
   "source": [
    "# إعدادات التدريب المحسنة لـ Mixtral\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=os.path.join(MODEL_SAVE_PATH, 'mixtral_sentiment_model'),\n",
    "    num_train_epochs=2,  # تقليل عدد العصور للنموذج الكبير\n",
    "    per_device_train_batch_size=1,  # حجم دفعة صغير للذاكرة\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=8,  # تجميع التدرجات\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=2e-4,  # معدل تعلم مناسب لـ LoRA\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=500,\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=100,\n",
    "    save_strategy='steps',\n",
    "    save_steps=500,\n",
    "    logging_dir=os.path.join(MODEL_SAVE_PATH, 'logs'),\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='accuracy',\n",
    "    save_total_limit=2,\n",
    "    report_to='none',\n",
    "    dataloader_pin_memory=False,\n",
    "    fp16=False,  # استخدام bfloat16 بدلاً من fp16\n",
    "    bf16=True,\n",
    "    gradient_checkpointing=True,  # توفير الذاكرة\n",
    "    dataloader_num_workers=0,  # تجنب مشاكل multiprocessing\n",
    "    remove_unused_columns=False,\n",
    "    optim='adamw_torch',\n",
    "    max_grad_norm=1.0,\n",
    ")\n",
    "\n",
    "print(f'مجلد حفظ النموذج: {training_args.output_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compute-metrics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"حساب مقاييس الأداء\"\"\"\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, predictions),\n",
    "        'f1': f1_score(labels, predictions, average='macro')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "runpod-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# إعدادات RunPod وتحسينات الذاكرة\n",
    "import gc\n",
    "import os\n",
    "\n",
    "# تنظيف الذاكرة\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# إعدادات البيئة لـ RunPod\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "# طباعة معلومات GPU\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name()}')\n",
    "    print(f'CUDA Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')\n",
    "    print(f'Available Memory: {torch.cuda.memory_reserved(0) / 1024**3:.1f} GB')\n",
    "else:\n",
    "    print('تحذير: لا يوجد GPU متاح!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# إنشاء المدرب وبدء التدريب\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# تحسين استخدام الذاكرة\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "print('بدء تدريب نموذج Mixtral-8x7B...')\n",
    "print(f'عدد المعاملات القابلة للتدريب: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}')\n",
    "\n",
    "# بدء التدريب مع معالجة الأخطاء\n",
    "try:\n",
    "    trainer.train()\n",
    "    print('تم الانتهاء من التدريب بنجاح!')\n",
    "except Exception as e:\n",
    "    print(f'خطأ أثناء التدريب: {e}')\n",
    "    # تنظيف الذاكرة في حالة الخطأ\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# حفظ النموذج المدرب\n",
    "print('حفظ النموذج...')\n",
    "\n",
    "# حفظ النموذج الأساسي\n",
    "trainer.save_model()\n",
    "\n",
    "# حفظ LoRA adapters\n",
    "model.save_pretrained(os.path.join(MODEL_SAVE_PATH, 'mixtral_lora_adapters'))\n",
    "\n",
    "# حفظ tokenizer\n",
    "tokenizer.save_pretrained(os.path.join(MODEL_SAVE_PATH, 'mixtral_tokenizer'))\n",
    "\n",
    "print(f'تم حفظ النموذج في: {MODEL_SAVE_PATH}')\n",
    "print('يمكنك الآن استخدام النموذج للتنبؤ!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classify-sentiment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sentiment(text):\n",
    "    \"\"\"تصنيف المشاعر للنص المدخل\"\"\"\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors='pt',\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=128\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        prediction = torch.argmax(logits, dim=1).item()\n",
    "        probabilities = torch.softmax(logits, dim=1)[0]\n",
    "    \n",
    "    label_map = {0: 'سلبي', 1: 'محايد', 2: 'إيجابي'}\n",
    "    confidence = probabilities[prediction].item()\n",
    "    \n",
    "    return {\n",
    "        'label': label_map[prediction],\n",
    "        'confidence': confidence,\n",
    "        'probabilities': {\n",
    "            'سلبي': probabilities[0].item(),\n",
    "            'محايد': probabilities[1].item(),\n",
    "            'إيجابي': probabilities[2].item()\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-sentiment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# اختبار النموذج\n",
    "test_texts = [\n",
    "    'هذا المنتج رائع جداً وأنصح به',\n",
    "    'المنتج سيء ولا أنصح بشرائه',\n",
    "    'المنتج عادي، لا بأس به',\n",
    "    'This product is amazing!',\n",
    "    'I hate this product'\n",
    "]\n",
    "\n",
    "print('=== اختبار النموذج ===')\n",
    "for text in test_texts:\n",
    "    result = classify_sentiment(text)\n",
    "    print(f'النص: {text}')\n",
    "    print(f'التصنيف: {result[\"label\"]} (ثقة: {result[\"confidence\"]:.2f})')\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-model-section",
   "metadata": {},
   "source": [
    "### تحميل النموذج المدرب في جلسة جديدة"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-trained-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# تحميل النموذج المدرب في جلسة جديدة\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "\n",
    "# مسارات النموذج\n",
    "base_model_path = 'mistralai/Mixtral-8x7B-Instruct-v0.1'\n",
    "lora_path = '/workspace/models/mixtral_lora_adapters'  # أو المسار المحفوظ\n",
    "tokenizer_path = '/workspace/models/mixtral_tokenizer'\n",
    "\n",
    "# تحميل tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "\n",
    "# تحميل النموذج الأساسي\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    base_model_path,\n",
    "    num_labels=3,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map='auto'\n",
    ")\n",
    "\n",
    "# تحميل LoRA adapters\n",
    "model = PeftModel.from_pretrained(base_model, lora_path)\n",
    "\n",
    "print('تم تحميل النموذج المدرب بنجاح!')\n",
    "print('يمكنك الآن استخدام دالة classify_sentiment للتنبؤ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}